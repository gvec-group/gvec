# =================================================================================================================================
# Stages to be executed, each stage is a collection of jobs pointing to the stage
# =================================================================================================================================

stages:
  - env
  - build
  - run
  - regression

workflow:
  name: 'Pipeline for branch $CI_COMMIT_REF_NAME and tag $HASH_TAG_RELEASE' #$CI_COMMIT_BRANCH

# =================================================================================================================================
# GLOBALS
# =================================================================================================================================

variables:
  GIT_STRATEGY: none #clone
  HASH_TAG: $CI_COMMIT_REF_NAME #$CI_COMMIT_BRANCH
  HASH_TAG_RELEASE: v0.0.1-dev #develop_mpi_par
#  GLOBAL_CACHE_PATH: "/home/gitlab-runner/globalcache/${CI_PIPELINE_ID}_${CI_COMMIT_REF_NAME}"

# =================================================================================================================================
# SHORT SYNTAX EXPLANATIONS FOR THE JOB, FOR DETAILS VISIT:    ===> https://docs.gitlab.com/ce/ci/yaml/   <===
# "stage:"         makes the job part of a stage defined above
# "tags:"          selects the runner
# "only:"          restricts the execution of the job to a git branch or tag
# "before_script:" shell commands to be executed before the main script.
# "script:"        shell commands for the test. If a shell command exits with >0, the job is marked as "failed", else as "passed".
#                  commands after a failing one are not executed anymore!
# "after_script:"  shell commands after passed OR failed script. Careful, the current directory is always the root of the repo!
# "artifacts:"     keep data from the job which is uploaded to gitlab.com. You really should set a duration to expiration.
#                  "when:" can be either on_failure, on_success or always
#
# => SCIPT SYNTAX CAN BE CHECKED ON GITLAB with the "CI LINT" tool
#
# =================================================================================================================================

# =================================================================================================================================
# ISSUE FOUND WITH PARALLEL MATRICES
# =================================================================================================================================

#  parallel:
#    matrix:
#      - CMP_MODE: ["Debug"]
#        OMP_MODE: ["ompON"] #only one element/variable in matrix: causes CI dependency line to break
#                             check issue report: https://gitlab.com/gitlab-org/gitlab/-/issues/428679
#                             workaround is to use the keyword "variables:" instead (like below) 
#  variables:
#    HASH_TAG: ${HASH_TAG_RELEASE}
#    CMP_MODE: "Debug"
#    OMP_MODE: "ompON"


# =================================================================================================================================
# TEMPLATES INDEPENDENT OF STAGE
# =================================================================================================================================

# ____________________________
# MPCDF new Docker images
# (each providing a toolchain based on a single combination of compiler and MPI variant)

# MPCDF Docker image intel_2023_1_0_x:latest
.tmpl_mpcdfci_intel2023:
  image: gitlab-registry.mpcdf.mpg.de/mpcdf/ci-module-image/intel_2023_1_0_x:latest
  tags:
    - shared
  variables:
    CMAKE_HOSTNAME: "mpcdfcirunner"
    CURR_CMP: "intel"

# MPCDF Docker image intel-impi:latest
.tmpl_mpcdfci_intel_impi_latest:
  image: gitlab-registry.mpcdf.mpg.de/mpcdf/ci-module-image/intel-impi:latest
  tags:
    - shared
  variables:
    CMAKE_HOSTNAME: "mpcdfcirunner"
    CURR_CMP: "intel_mpi"

# MPCDF Docker image gcc_13:latest
.tmpl_mpcdfci_gcc13:
  image: gitlab-registry.mpcdf.mpg.de/mpcdf/ci-module-image/gcc_13:latest
  tags:
    - shared
  variables:
    CMAKE_HOSTNAME: "mpcdfcirunner"
    CURR_CMP: "gnu"

# MPCDF Docker image gcc-openmpi:latest
.tmpl_mpcdfci_gcc_openmpi_latest:
  image: gitlab-registry.mpcdf.mpg.de/mpcdf/ci-module-image/gcc-openmpi:latest
  tags:
    - shared
  variables:
    CMAKE_HOSTNAME: "mpcdfcirunner"
    CURR_CMP: "gnu_mpi"

# ____________________________
# MPCDF older Docker image

# MPCDF shared runner (module-image, soon legacy, then deprecated)
.tmpl_sharedrunner:
  image: gitlab-registry.mpcdf.mpg.de/mpcdf/module-image
  tags:
    - shared
  variables:
    CMAKE_HOSTNAME: "sharedrunner"

# MPCDF testimonytwo runner
.tmpl_testimony:
  tags:
    - vm_linux
  variables:
    CMAKE_HOSTNAME: "testimony"

# ____________________________
# bash scripts to load modules

.tmpl_before_script_modules:
  before_script:
    - . ./CI_setup/${CMAKE_HOSTNAME}_setup_${CURR_CMP}


# =================================================================================================================================
# TEMPLATES FOR STAGE "env" (printout the enviroment for future reference)
# =================================================================================================================================

.tmpl_script_env:
  script:
    - echo "Pipeline environment for branch:" $CI_COMMIT_REF_NAME #$CI_COMMIT_BRANCH
    - echo $CI_RUNNER_DESCRIPTION
    - echo $CI_RUNNER_TAGS
    - printenv
    - module avail
    - echo $OMP_NUM_THREADS


# =================================================================================================================================
# TEMPLATES FOR STAGE "build" 
# =================================================================================================================================

# ____________________________
# ${CI_COMMIT_REF_NAME} branch/tag (CI trigger commit)

.vars_matrix_build:
  parallel:
    matrix:
      - CMP_MODE: ["Debug", "Release"]
        OMP_MODE: ["ompOFF", "ompON"]
  variables:
    MPI_MODE: "mpiOFF"

.vars_matrix_mpi_build:
  parallel:
    matrix:
      - CMP_MODE: ["Debug", "Release"]
        OMP_MODE: ["ompOFF", "ompON"]
  variables:
    MPI_MODE: "mpiON"
    MPI_RNKS_MODE: "_nranks${MPI_RNKS}"

# ____________________________
# ${HASH_TAG} branch (release version)

.vars_matrix_build_tag:
  parallel:
    matrix:
      - CMP_MODE: ["Debug"]
        OMP_MODE: ["ompOFF", "ompON"]
  variables:
    HASH_TAG: ${HASH_TAG_RELEASE}
    MPI_MODE: "mpiOFF"

.vars_matrix_mpi_build_tag:
  parallel:
    matrix:
      - CMP_MODE: ["Debug"]
        OMP_MODE: ["ompOFF", "ompON"]
  variables:
    HASH_TAG: ${HASH_TAG_RELEASE}
    MPI_MODE: "mpiON"
    MPI_RNKS_MODE: "_nranks${MPI_RNKS}"

# ____________________________
# Independent of ${HASH_TAG}

.tmpl_setup_build:
  variables:
    GIT_STRATEGY: clone
    BUILDNAME: ${HASH_TAG}_${CURR_CMP}_${CMP_MODE}_${OMP_MODE}_${MPI_MODE}

.tmpl_before_script_build:
  before_script:
#    - mkdir develop && cd develop && cp -R ../.git ./
#    - git checkout -- . && git branch --all
#    - git checkout develop_mpi_par
#    - cd ..
    - pwd
    - echo "Building on branch ${HASH_TAG} with ${CURR_CMP} in ${CMP_MODE} mode, OMP=${OMP_MODE:3} and MPI=${MPI_MODE:3}"
    - echo "CMAKE_HOSTNAME is ${CMAKE_HOSTNAME}"
    - echo "is ${HASH_TAG} the same as ${CI_COMMIT_REF_NAME}?"                        #${CI_COMMIT_BRANCH}
    - if [ ${HASH_TAG} != ${CI_COMMIT_REF_NAME} ]; then git checkout ${HASH_TAG}; fi  #${CI_COMMIT_BRANCH}
    - echo "BUILDNAME is ${BUILDNAME}"
    - rm -rf build_${BUILDNAME}; mkdir -p build_${BUILDNAME}
    - cd build_${BUILDNAME}; pwd
    - echo "cmake -DCMAKE_HOSTNAME=${CMAKE_HOSTNAME} -DCMAKE_BUILD_TYPE=${CMP_MODE} -DCOMPILE_GVEC=ON -DLINK_GVEC_TO_NETCDF=ON -DUSE_OPENMP=${OMP_MODE:3} -DUSE_MPI=${MPI_MODE:3} -DCOMPILE_GVEC_AS_STATIC_LIB=ON ../."

.tmpl_script_build:
  script:
    # only compile gvec
    #- cmake -DCMAKE_HOSTNAME=${CMAKE_HOSTNAME} -DCMAKE_BUILD_TYPE=${CMP_MODE} -DCOMPILE_GVEC=ON -DCOMPILE_GVEC_TO_CASTOR3D=ON -DCOMPILE_GVEC_TO_GENE=ON -DCOMPILE_GVEC_TO_JOREK=ON -DCOMPILE_GVEC_TO_HOPR=ON -DLINK_GVEC_TO_NETCDF=ON -DUSE_OPENMP=${OMP_MODE} ../. |tee ../log_${BUILDNAME}_cmake.txt
    - cmake -DCMAKE_HOSTNAME=${CMAKE_HOSTNAME} -DCMAKE_BUILD_TYPE=${CMP_MODE} -DCOMPILE_GVEC=ON -DLINK_GVEC_TO_NETCDF=ON -DUSE_OPENMP=${OMP_MODE:3} -DUSE_MPI=${MPI_MODE:3} -DCOMPILE_GVEC_AS_STATIC_LIB=ON ../. |tee ../log_${BUILDNAME}_cmake.txt
    - make -j |tee ../log_${BUILDNAME}_make.txt
    - cd ..; echo "... BUILD PHASE FINISHED!"
  artifacts:
    name: "${CI_PIPELINE_ID}_${BUILDNAME}"
#    name: "${HASH_TAG}_${CI_PIPELINE_ID}_${BUILDNAME}"
    paths:
      - build_${BUILDNAME}
      - log_${BUILDNAME}_*.txt
#      - CI_setup
#      - gitlab_*.py
    expire_in: 1 week
    when: always
#    when: on_failure


# =================================================================================================================================
# TEMPLATES FOR STAGE "run"
# =================================================================================================================================

# ____________________________
# ${CI_COMMIT_REF_NAME} branch (CI trigger commit)

.vars_matrix_run:
  parallel:
    matrix:
      - CMP_MODE: ["Debug"]
        OMP_MODE: ["ompOFF","ompON"]
  variables:
    MPI_MODE: "mpiOFF"
    MPI_RNKS_MODE: ""

# there are different issues with MPI_RNKS>4 in both runners
.vars_matrix_mpi_run:
  parallel:
    matrix:
      - CMP_MODE: ["Debug"]
        OMP_MODE: ["ompOFF","ompON"]
        MPI_RNKS: ["1","2"]
  variables:
    MPI_MODE: "mpiON"
    MPI_RNKS_MODE: "_nranks${MPI_RNKS}"

# ____________________________
# ${HASH_TAG} branch (release version)

.vars_matrix_run_tag:
  parallel:
    matrix:
      - OMP_MODE: ["ompOFF","ompON"]
  variables:
    HASH_TAG: ${HASH_TAG_RELEASE}
    CMP_MODE: "Debug"
    MPI_MODE: "mpiOFF"
    MPI_RNKS_MODE: ""


.vars_matrix_mpi_run_tag:
  parallel:
    matrix:
      - CMP_MODE: ["Debug"]
        OMP_MODE: ["ompOFF","ompON"]
        MPI_RNKS: ["1","2"]
  variables:
    HASH_TAG: ${HASH_TAG_RELEASE}
    MPI_MODE: "mpiON"
    MPI_RNKS_MODE: "_nranks${MPI_RNKS}"


# ____________________________
# Independent of ${HASH_TAG}

.tmpl_setup_run:
  variables:
    GIT_STRATEGY: clone
    BUILDNAME: ${HASH_TAG}_${CURR_CMP}_${CMP_MODE}_${OMP_MODE}_${MPI_MODE}
    CASENAME: ${HASH_TAG}_${CURR_CMP}_${CMP_MODE}_${OMP_MODE}_${MPI_MODE}${MPI_RNKS_MODE}

.tmpl_before_script_run:
  before_script:
#      line below is needed if MPI_RANKS>6 cores are requested
#    - if [ ${CURR_CMP} = 'gnu_mpi' ]; if [ ${MPI_RNKS} -gt '4' ]; then export MPI_PRFX="mpirun --host ${HOSTNAME}:${MPI_RNKS} -np ${MPI_RNKS}"; fi; fi
    - if [ ${MPI_MODE} = 'mpiON' ]; then export MPI_PRFX="mpirun -np ${MPI_RNKS}"; else export MPI_PRFX=""; fi
    - if [ ${OMP_MODE} = 'ompON' ]; then export OMP_NUM_THREADS=2; fi
    - echo ${HOSTNAME}
    - export EXECPRE="${MPI_PRFX}"
    - echo "HASH_TAG is ${HASH_TAG}"
#not needed    - if [ ${HASH_TAG} != ${CI_COMMIT_REF_NAME} ]; then git checkout ${HASH_TAG}; fi  #${CI_COMMIT_BRANCH}
    - echo "BUILDNAME is ${BUILDNAME} >> build_${BUILDNAME}/"
    - echo "CASENAME is ${CASENAME} >> shortruns_${CASENAME}/"
    - rm -rf shortruns_${CASENAME}; mkdir -p shortruns_${CASENAME}
    - echo "Running with $CURR_CMP in $CMP_MODE mode, OMP=${OMP_MODE:3} and MPI=${MPI_MODE:3}"
    - python --version
    - echo "python gitlab_shortruns.py -case 1 -execdir shortruns_${CASENAME} -execpre "${EXECPRE}" build_${BUILDNAME}"

.tmpl_script_run:
  script:
    #- time python gitlab_shortruns.py -execdir shortruns_${CASENAME} build_${CASENAME} |tee log_${CASENAME}_shortruns.txt
    # only execute case 1 for now...
    - time python gitlab_shortruns.py -case 1 -execdir shortruns_${CASENAME} -execpre "${EXECPRE}" build_${BUILDNAME} |tee log_${CASENAME}_shortruns.txt
  artifacts:
#    name: "${HASH_TAG}_${CI_PIPELINE_ID}_${CASENAME}"
    name: "${CASENAME}"
    paths:
      - log_${CASENAME}_shortruns.txt
      - shortruns_${CASENAME}
    expire_in: 1 week
    when: always
#    when: on_failure


# =================================================================================================================================
# TEMPLATES FOR STAGE "regression"
# =================================================================================================================================

.tmpl_script_regression:
  variables:
    GIT_STRATEGY: fetch
  script:
    - numdiff --version
    - echo shortruns_${CASENAME_1}
    - echo shortruns_${CASENAME_2}
    - python gitlab_regressions.py shortruns_${CASENAME_1} shortruns_${CASENAME_2}
  artifacts:
    name: "${CASENAME_1}_vs_${CASENAME_2}"
    paths:
      - log_compare_*.txt
      - tmp*
      - std*
    expire_in: 1 week
    when: on_failure


# =================================================================================================================================
# Stage "env"
# =================================================================================================================================

# printout MPCDF Docker (Intel 2023) shared runner environment
mpcdfci_intel2023_env:
  stage: env
  extends:
    - .tmpl_mpcdfci_intel2023
    - .tmpl_script_env

# printout MPCDF Docker (intel-impi:latest) shared runner environment
mpcdfci_intel_impi_latest_env:
  stage: env
  extends:
    - .tmpl_mpcdfci_intel_impi_latest
    - .tmpl_script_env

# printout MPCDF Docker (GCC 13) shared runner environment
mpcdfci_gcc13_env:
  stage: env
  extends:
    - .tmpl_mpcdfci_gcc13
    - .tmpl_script_env

mpcdfci_gcc_openmpi_latest_env:
  stage: env
  extends:
    - .tmpl_mpcdfci_gcc_openmpi_latest
    - .tmpl_script_env

# printout MPCDF shared runner environment
sharedrunner_env:
  stage: env
  extends:
    - .tmpl_sharedrunner
    - .tmpl_script_env

# printout MPCDF testimonytwo runner environment
testimony_env:
  stage: env
  extends:
    - .tmpl_testimony
    - .tmpl_script_env


# =================================================================================================================================
# Stage "build"
# =================================================================================================================================

# ---------------------------------------------------------------------------------------------------------------------------------
# GitLab Shared Runners

# ____________________________
# ${CI_COMMIT_REF_NAME} branch (CI trigger commit)

# ____________________________
# MPCDF new Docker images
# (each providing a toolchain based on a single combination of compiler and MPI variant)

# build with MPCDF Docker (Intel 2023) shared runner environment
mpcdfci_intel2023_build:
  stage: build
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_build","before_script"]
  extends:
    - .tmpl_mpcdfci_intel2023
    - .tmpl_setup_build
    - .tmpl_script_build
    - .vars_matrix_build  # matrix of variables
#mr  variables:
#mr    CURR_CMP: "intel"
#mr    MPI_MODE: "mpiOFF"
  needs: [mpcdfci_intel2023_env]
#  needs: [] # set the job to start as soon as the pipeline is created

# build with MPCDF Docker (GCC 13) shared runner environment
mpcdfci_gcc13_build:
  stage: build
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_build","before_script"]
  extends:
    - .tmpl_mpcdfci_gcc13
    - .tmpl_setup_build
    - .tmpl_script_build
    - .vars_matrix_build  # matrix of variables
#mr  variables:
#mr    CURR_CMP: "gnu"
#mr    MPI_MODE: "mpiOFF"
  needs: [mpcdfci_gcc13_env]

# build with MPCDF Docker (intel-impi:latest) shared runner environment
mpcdfci_intel_impi_latest_build:
  stage: build
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_build","before_script"]
  extends:
    - .tmpl_mpcdfci_intel_impi_latest
    - .tmpl_setup_build
    - .tmpl_script_build
    - .vars_matrix_mpi_build  # matrix of variables
#mr  variables:
#mr    CURR_CMP: "intel_mpi"
#mr    MPI_MODE: "mpiON"
  needs: [mpcdfci_intel_impi_latest_env]

# build with MPCDF Docker (gcc-openmpi:latest) shared runner environment
mpcdfci_gcc_openmpi_latest_build:
  stage: build
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_build","before_script"]
  extends:
    - .tmpl_mpcdfci_gcc_openmpi_latest
    - .tmpl_setup_build
    - .tmpl_script_build
    - .vars_matrix_mpi_build  # matrix of variables
#mr  variables:
#mr    CURR_CMP: "gnu_mpi"
#mr    MPI_MODE: "mpiON"
  needs: [mpcdfci_gcc_openmpi_latest_env]

# ____________________________
# MPCDF older Docker image

# build with Intel on MPCDF shared runner
sharedrunner_intel_build:
  stage: build
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_build","before_script"]
  extends:
    - .tmpl_sharedrunner
    - .tmpl_setup_build
    - .tmpl_script_build
    - .vars_matrix_build  # matrix of variables
  variables:
    CURR_CMP: "intel"
    MPI_MODE: "mpiOFF"
  needs: [sharedrunner_env] # set the job to start as soon as the pipeline is created

# build with GNU on MPCDF shared runner
sharedrunner_gnu_build:
  stage: build
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_build","before_script"]
  extends:
    - .tmpl_sharedrunner
    - .tmpl_setup_build
    - .tmpl_script_build
    - .vars_matrix_build  # matrix of variables
  variables:
    CURR_CMP: "gnu"
#mr    MPI_MODE: "mpiOFF"
  needs: [sharedrunner_env] # set the job to start as soon as the pipeline is created

# build with Intel and MPI on MPCDF shared runner
sharedrunner_intel_mpi_build:
  stage: build
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_build","before_script"]
  extends:
    - .tmpl_sharedrunner
    - .tmpl_setup_build
    - .tmpl_script_build
    - .vars_matrix_mpi_build  # matrix of variables
  variables:
    CURR_CMP: "intel_mpi"
#mr    MPI_MODE: "mpiON"
  needs: [sharedrunner_env]
###  needs: [] # set the job to start as soon as the pipeline is created

## build with GNU and MPI on MPCDF shared runner
#sharedrunner_gnu_mpi_build:
#  stage: build
#  before_script:
#    - !reference [".tmpl_before_script_modules", "before_script"]
#    - !reference [".tmpl_before_script_build","before_script"]
#  extends:
#    - .tmpl_sharedrunner
#    - .tmpl_setup_build
#    - .tmpl_script_build
#    - .vars_matrix_mpi_build  # matrix of variables
#  variables:
#    CURR_CMP: "gnu_mpi"
#mr#    MPI_MODE: "mpiON"
#  needs: [sharedrunner_env]
####  needs: [] # set the job to start as soon as the pipeline is created

# ____________________________
# ${HASH_TAG} branch (release version)

# build (TAG) with MPCDF Docker (Intel 2023) shared runner environment
mpcdfci_intel2023_build_tag:
  stage: build
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_build","before_script"]
  extends:
    - .tmpl_mpcdfci_intel2023
    - .tmpl_setup_build
    - .tmpl_script_build
    - .vars_matrix_build_tag  # matrix of variables
#mr  variables:
#mr    CURR_CMP: "intel"
#mr    MPI_MODE: "mpiOFF"
  needs: [mpcdfci_intel2023_env] # set the job to start as soon as the pipeline is created

# build (TAG) with MPCDF Docker (intel-impi:latest) shared runner environment
mpcdfci_intel_impi_latest_build_tag:
  stage: build
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_build","before_script"]
  extends:
    - .tmpl_mpcdfci_intel_impi_latest
    - .tmpl_setup_build
    - .tmpl_script_build
    - .vars_matrix_mpi_build_tag  # matrix of variables
#mr  variables:
#mr    CURR_CMP: "intel_mpi"
#mr    MPI_MODE: "mpiON"
  needs: [mpcdfci_intel_impi_latest_env] # set the job to start as soon as the pipeline is created

# build with Intel on MPCDF shared runner
sharedrunner_intel_build_tag:
  stage: build
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_build","before_script"]
  extends:
    - .tmpl_sharedrunner
    - .tmpl_setup_build
    - .tmpl_script_build
    - .vars_matrix_build_tag  # matrix of variables
  variables:
    CURR_CMP: "intel"
#mr    MPI_MODE: "mpiOFF"
  needs: [sharedrunner_env] # set the job to start as soon as the pipeline is created

# build with Intel and MPI on MPCDF shared runner
sharedrunner_intel_mpi_build_tag:
  stage: build
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_build","before_script"]
  extends:
    - .tmpl_sharedrunner
    - .tmpl_setup_build
    - .tmpl_script_build
    - .vars_matrix_mpi_build_tag  # matrix of variables
  variables:
    CURR_CMP: "intel_mpi"
#mr    MPI_MODE: "mpiON"
  needs: [sharedrunner_env] # set the job to start as soon as the pipeline is created


# ---------------------------------------------------------------------------------------------------------------------------------
# GitLab Testimonytwo Runner

# ____________________________
# ${CI_COMMIT_REF_NAME} branch (CI trigger commit)

# build with Intel on MPCDF testimonytwo runner
testimony_intel_build:
  stage: build
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_build","before_script"]
  extends:
    - .tmpl_testimony
    - .tmpl_setup_build
    - .tmpl_script_build
    - .vars_matrix_build  # matrix of variables
  variables:
    CURR_CMP: "intel"
#mr    MPI_MODE: "mpiOFF"
  needs: [testimony_env] # set the job to start as soon as the pipeline is created

## build with GNU on MPCDF testimonytwo runner
#testimony_gnu_build:
#  stage: build
#  before_script:
#    - !reference [".tmpl_before_script_modules", "before_script"]
#    - !reference [".tmpl_before_script_build","before_script"]
#  extends:
#    - .tmpl_testimony
#    - .tmpl_setup_build
#    - .tmpl_script_build
#  variables:
#    CURR_CMP: "gnu"
##mr    MPI_MODE: "mpiOFF"
#  needs: [testimony_env] # set the job to start as soon as the pipeline is created

## build with Intel and MPI on MPCDF testimonytwo runner
#testimony_intel_mpi_build:
#  stage: build
#  before_script:
#    - !reference [".tmpl_before_script_modules", "before_script"]
#    - !reference [".tmpl_before_script_build","before_script"]
#  extends:
#    - .tmpl_testimony
#    - .tmpl_setup_build
#    - .tmpl_script_build
#  variables:
#    CURR_CMP: "intel_mpi"
##mr    MPI_MODE: "mpiON"
#  needs: [testimony_env] # set the job to start as soon as the pipeline is created
####  needs: [testimony_env]

## build with GNU and MPI on MPCDF testimonytwo runner
#testimony_gnu_mpi_build:
#  stage: build
#  before_script:
#    - !reference [".tmpl_before_script_modules", "before_script"]
#    - !reference [".tmpl_before_script_build","before_script"]
#  extends:
#    - .tmpl_testimony
#    - .tmpl_setup_build
#    - .tmpl_script_build
#  variables:
#    CURR_CMP: "gnu_mpi"
##mr    MPI_MODE: "mpiON"
#  needs: [testimony_env] # set the job to start as soon as the pipeline is created

# =================================================================================================================================
# Stage "run"
# =================================================================================================================================

# ---------------------------------------------------------------------------------------------------------------------------------
# GitLab Shared Runners

# ____________________________
# ${CI_COMMIT_REF_NAME} branch (CI trigger commit)

# ____________________________
# MPCDF new Docker images
# (each providing a toolchain based on a single combination of compiler and MPI variant)

# run with MPCDF Docker (intel2023) shared runner environment
mpcdfci_intel2023_run:
  stage: run
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_run", "before_script"]
  extends:
    - .tmpl_mpcdfci_intel2023
    - .tmpl_setup_run
    - .tmpl_script_run
    - .vars_matrix_run  # matrix of variables
#mr  variables:
#mr    CURR_CMP: "intel"
  needs:
    - job: mpcdfci_intel2023_build
      artifacts: true

# run with MPCDF Docker (gcc13) shared runner environment
mpcdfci_gcc13_run:
  stage: run
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_run", "before_script"]
  extends:
    - .tmpl_mpcdfci_gcc13
    - .tmpl_setup_run
    - .tmpl_script_run
    - .vars_matrix_run  # matrix of variables
#mr  variables:
#mr    CURR_CMP: "gnu"
  needs:
    - job: mpcdfci_gcc13_build
      artifacts: true

# run with MPCDF Docker (intel-impi:latest) shared runner environment
mpcdfci_intel_impi_latest_run:
  stage: run
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_run", "before_script"]
  extends:
    - .tmpl_mpcdfci_intel_impi_latest
    - .tmpl_setup_run
    - .tmpl_script_run
    - .vars_matrix_mpi_run  # matrix of variables
#mr  variables:
#mr    CURR_CMP: "intel_mpi"  # _mpi must be used together with .vars_matrix_mpi_run above
  needs:
    - job: mpcdfci_intel_impi_latest_build
      artifacts: true

# run with MPCDF Docker (gcc-openmpi:latest) shared runner environment
mpcdfci_gcc_openmpi_latest_run:
  stage: run
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_run", "before_script"]
  extends:
    - .tmpl_mpcdfci_gcc_openmpi_latest
    - .tmpl_setup_run
    - .tmpl_script_run
    - .vars_matrix_mpi_run  # matrix of variables
#mr  variables:
#mr    CURR_CMP: "gnu_mpi"  # _mpi must be used together with .vars_matrix_mpi_run above
  needs:
    - job: mpcdfci_gcc_openmpi_latest_build
      artifacts: true

# run with Intel on MPCDF shared runner
sharedrunner_intel_run:
  stage: run
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_run", "before_script"]
  extends:
    - .tmpl_sharedrunner
    - .tmpl_setup_run
    - .tmpl_script_run
    - .vars_matrix_run  # matrix of variables
  variables:
    CURR_CMP: "intel"
  needs:
    - job: sharedrunner_intel_build
      artifacts: true

# run with GNU on MPCDF shared runner
sharedrunner_gnu_run:
  stage: run
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_run", "before_script"]
  extends:
    - .tmpl_sharedrunner
    - .tmpl_setup_run
    - .tmpl_script_run
    - .vars_matrix_run  # matrix of variables
  variables:
    CURR_CMP: "gnu"
  needs:
    - job: sharedrunner_gnu_build
      artifacts: true

# run with Intel on MPCDF shared runner
sharedrunner_intel_mpi_run:
  stage: run
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_run", "before_script"]
  extends:
    - .tmpl_sharedrunner
    - .tmpl_setup_run
    - .tmpl_script_run
    - .vars_matrix_mpi_run  # matrix of variables
  variables:
    CURR_CMP: "intel_mpi"  # _mpi must be used together with .vars_matrix_mpi_run above
  needs:
    - job: sharedrunner_intel_mpi_build
      artifacts: true

## run with GNU on MPCDF shared runner
#sharedrunner_gnu_mpi_run:
#  stage: run
#  needs:
#    - job: sharedrunner_gnu_mpi_build
#      artifacts: true
#  before_script:
#    - !reference [".tmpl_before_script_modules", "before_script"]
#    - !reference [".tmpl_before_script_run", "before_script"]
#  extends:
#    - .tmpl_sharedrunner
##b    - .tmpl_setup_run_mpi
#    - .tmpl_setup_run
#    - .tmpl_script_run
#    - .vars_matrix_mpi_run  # matrix of variables
#  variables:
#    CURR_CMP: "gnu_mpi"  # _mpi must be used together with .vars_matrix_mpi_run above

# ____________________________
# ${HASH_TAG} branch (release version)

# run with MPCDF Docker (intel2023) shared runner environment
mpcdfci_intel2023_run_tag:
  stage: run
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_run", "before_script"]
  extends:
    - .tmpl_mpcdfci_intel2023
    - .tmpl_setup_run
    - .tmpl_script_run
    - .vars_matrix_run_tag  # matrix of variables
#mr  variables:
#mr    CURR_CMP: "intel"
  needs:
    - job: mpcdfci_intel2023_build_tag
      artifacts: true

# run with MPCDF Docker (intel-impi:latest) shared runner environment
mpcdfci_intel_impi_latest_run_tag:
  stage: run
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_run", "before_script"]
  extends:
    - .tmpl_mpcdfci_intel_impi_latest
    - .tmpl_setup_run
    - .tmpl_script_run
    - .vars_matrix_mpi_run_tag  # matrix of variables
#mr  variables:
#mr    CURR_CMP: "intel_mpi"  # _mpi must be used together with .vars_matrix_mpi_run above
  needs:
    - job: mpcdfci_intel_impi_latest_build_tag
      artifacts: true


# run with Intel on MPCDF shared runner
sharedrunner_intel_run_tag:
  stage: run
#      parallel:
#        matrix:
#          - CMP_MODE: ["Debug"]
#            OMP_MODE: ["ompON"]
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_run", "before_script"]
  extends:
    - .tmpl_sharedrunner
    - .tmpl_setup_run
    - .tmpl_script_run
    - .vars_matrix_run_tag  # matrix of variables
  variables:
    CURR_CMP: "intel"
  needs:
    - job: sharedrunner_intel_build_tag
      artifacts: true

# run with Intel on MPCDF shared runner
sharedrunner_intel_mpi_run_tag:
  stage: run
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_run", "before_script"]
  extends:
    - .tmpl_sharedrunner
    - .tmpl_setup_run
    - .tmpl_script_run
    - .vars_matrix_mpi_run_tag  # matrix of variables
  variables:
    CURR_CMP: "intel_mpi"  # _mpi must be used together with .vars_matrix_mpi_run above
  needs:
    - job: sharedrunner_intel_mpi_build_tag
      artifacts: true


# ---------------------------------------------------------------------------------------------------------------------------------
# GitLab Testimonytwo Runner

# ____________________________
# ${CI_COMMIT_REF_NAME} branch (CI trigger commit)

# run with Intel on MPCDF testimonytwo runner
testimony_intel_run:
  stage: run
  before_script:
    - !reference [".tmpl_before_script_modules", "before_script"]
    - !reference [".tmpl_before_script_run", "before_script"]
  extends:
    - .tmpl_testimony
    - .tmpl_setup_run
    - .tmpl_script_run
    - .vars_matrix_run  # matrix of variables
  variables:
    CURR_CMP: "intel"
  needs:
    - job: testimony_intel_build
      artifacts: true

## run with GNU on MPCDF testimonytwo runner
#testimony_gnu_run:
#  stage: run
#  before_script:
#    - !reference [".tmpl_before_script_modules", "before_script"]
#    - !reference [".tmpl_before_script_run", "before_script"]
#  extends:
#    - .tmpl_testimony
#    - .tmpl_setup_run
#    - .tmpl_script_run
#  variables:
#    CURR_CMP: "gnu"
#  needs:
#    - job: testimony_gnu_build
#      artifacts: true

## run with Intel on MPCDF testimonytwo runner
#testimony_intel_mpi_run:
#  stage: run
#  before_script:
#    - !reference [".tmpl_before_script_modules", "before_script"]
#    - !reference [".tmpl_before_script_run", "before_script"]
#  extends:
#    - .tmpl_testimony
#    - .tmpl_setup_run_mpi
#    - .tmpl_script_run
#  variables:
#    CURR_CMP: "intel_mpi"  # _mpi must be used together with .vars_matrix_mpi_run above
#  needs:
#    - job: testimony_intel_mpi_build
#      artifacts: true

## run with GNU on MPCDF testimonytwo runner
#testimony_gnu_mpi_run:
#  stage: run
#  before_script:
#    - !reference [".tmpl_before_script_modules", "before_script"]
#    - !reference [".tmpl_before_script_run", "before_script"]
#    - module list
#  extends:
#    - .tmpl_testimony
#    - .tmpl_setup_run_mpi
#    - .tmpl_script_run
#  variables:
#    CURR_CMP: "gnu_mpi"  # _mpi must be used together with .vars_matrix_mpi_run above
#  needs:
#    - job: testimony_gnu_mpi_build
#      artifacts: true

# =================================================================================================================================
# Stage "regression"
# =================================================================================================================================

# ---------------------------------------------------------------------------------------------------------------------------------
# GitLab Shared Runners

# ____________________________
# MPCDF new Docker images
# (each providing a toolchain based on a single combination of compiler and MPI variant)


# compare results between current and tag branches (no MPI)
mpcdfci_intel_regression_tag:
  stage: regression
  extends:
    - .tmpl_mpcdfci_intel2023      # need to choose one (does not matter which) Docker image
    - .tmpl_before_script_modules # need to load modules (numdiff cmd!)
    - .tmpl_script_regression
  parallel:
    matrix:
      - CMP_MODE: ["Debug"]
        OMP_MODE: ["ompOFF","ompON"]
  variables:
#    GIT_STRATEGY: fetch
    CURR_CMP: intel # needed to load modules (numdiff cmd!)
    HASH_TAG_1: ${HASH_TAG}
    HASH_TAG_2: ${HASH_TAG_RELEASE}
    CURR_CMP_1: ${CURR_CMP}
    CURR_CMP_2: ${CURR_CMP}
    CASENAME_1: ${HASH_TAG_1}_${CURR_CMP_1}_${CMP_MODE}_${OMP_MODE}_mpiOFF
    CASENAME_2: ${HASH_TAG_2}_${CURR_CMP_2}_${CMP_MODE}_${OMP_MODE}_mpiOFF
  needs:
    - job: mpcdfci_intel2023_run
      artifacts: true
    - job: mpcdfci_intel2023_run_tag
      artifacts: true


# compare results between intel and gnu on current branches
mpcdfci_intel_mpi_regression:
  stage: regression
  script:
    - numdiff --version
    - echo shortruns_${CASENAME_1}
    - echo shortruns_${CASENAME_2}
    - python gitlab_regressions.py shortruns_${CASENAME_1} shortruns_${CASENAME_2}
  extends:
    - .tmpl_mpcdfci_intel2023      # need to choose one (does not matter which) Docker image
    - .tmpl_before_script_modules # need to load modules (numdiff cmd!)
    - .tmpl_script_regression
  parallel:
    matrix:
      - CMP_MODE: ["Debug"]
        OMP_MODE: ["ompOFF","ompON"]
  variables:
    GIT_STRATEGY: fetch
    CURR_CMP: intel # needed to load modules (numdiff cmd!)
    HASH_TAG_1: ${HASH_TAG}
    HASH_TAG_2: ${HASH_TAG}
    CURR_CMP_1: ${CURR_CMP}
    CURR_CMP_2: ${CURR_CMP}_mpi
    CASENAME_1: ${HASH_TAG_1}_${CURR_CMP_1}_${CMP_MODE}_${OMP_MODE}_mpiOFF
    CASENAME_2: ${HASH_TAG_2}_${CURR_CMP_2}_${CMP_MODE}_${OMP_MODE}_mpiON_nranks2
  needs:
    - job: mpcdfci_intel2023_run
      artifacts: true
    - job: mpcdfci_intel_impi_latest_run
      artifacts: true


# compare results between intel and gnu on current branches (no MPI)
mpcdfci_intel_gnu_regression:
  stage: regression
  extends:
    - .tmpl_mpcdfci_intel2023      # need to choose one (does not matter which) Docker image
    - .tmpl_before_script_modules # need to load modules (numdiff cmd!)
    - .tmpl_script_regression
  parallel:
    matrix:
      - CMP_MODE: ["Debug"]
        OMP_MODE: ["ompOFF","ompON"]
  variables:
    CURR_CMP: intel # needed to load modules (numdiff cmd!)
    HASH_TAG_1: ${HASH_TAG}
    HASH_TAG_2: ${HASH_TAG}
    CURR_CMP_1: ${CURR_CMP}
    CURR_CMP_2: gnu
    CASENAME_1: ${HASH_TAG_1}_${CURR_CMP_1}_${CMP_MODE}_${OMP_MODE}_mpiOFF
    CASENAME_2: ${HASH_TAG_2}_${CURR_CMP_2}_${CMP_MODE}_${OMP_MODE}_mpiOFF
  needs:
    - job: mpcdfci_intel2023_run
      artifacts: true
    - job: mpcdfci_gcc13_run
      artifacts: true

# ____________________________
# MPCDF older Docker image

# compare results between current and tag branches (no MPI)
shared_intel_regression_tag:
  stage: regression
  extends:
    - .tmpl_sharedrunner          # needed to load modules (numdiff cmd!)
    - .tmpl_before_script_modules # needed to load modules (numdiff cmd!)
    - .tmpl_script_regression
  parallel:
    matrix:
      - CMP_MODE: ["Debug"]
        OMP_MODE: ["ompOFF","ompON"]
  variables:
#    GIT_STRATEGY: fetch
    CURR_CMP: intel # needed to load modules (numdiff cmd!)
    HASH_TAG_1: ${HASH_TAG}
    HASH_TAG_2: ${HASH_TAG_RELEASE}
    CURR_CMP_1: ${CURR_CMP}
    CURR_CMP_2: ${CURR_CMP}
    CASENAME_1: ${HASH_TAG_1}_${CURR_CMP_1}_${CMP_MODE}_${OMP_MODE}_mpiOFF
    CASENAME_2: ${HASH_TAG_2}_${CURR_CMP_2}_${CMP_MODE}_${OMP_MODE}_mpiOFF
  needs:
    - job: sharedrunner_intel_run
      artifacts: true
    - job: sharedrunner_intel_run_tag
      artifacts: true

# compare results between intel and gnu on current branches
shared_intel_mpi_regression:
  stage: regression
  script:
    - numdiff --version
    - echo shortruns_${CASENAME_1}
    - echo shortruns_${CASENAME_2}
    - python gitlab_regressions.py shortruns_${CASENAME_1} shortruns_${CASENAME_2}
  extends:
    - .tmpl_sharedrunner          # needed to load modules (numdiff cmd!)
    - .tmpl_before_script_modules # needed to load modules (numdiff cmd!)
    - .tmpl_script_regression
  parallel:
    matrix:
      - CMP_MODE: ["Debug"]
        OMP_MODE: ["ompOFF","ompON"]
  variables:
    GIT_STRATEGY: fetch
    CURR_CMP: intel # needed to load modules (numdiff cmd!)
    HASH_TAG_1: ${HASH_TAG}
    HASH_TAG_2: ${HASH_TAG}
    CURR_CMP_1: ${CURR_CMP}
    CURR_CMP_2: ${CURR_CMP}_mpi
    CASENAME_1: ${HASH_TAG_1}_${CURR_CMP_1}_${CMP_MODE}_${OMP_MODE}_mpiOFF
    CASENAME_2: ${HASH_TAG_2}_${CURR_CMP_2}_${CMP_MODE}_${OMP_MODE}_mpiON_nranks2
  needs:
    - job: sharedrunner_intel_run
      artifacts: true
    - job: sharedrunner_intel_mpi_run
      artifacts: true


# compare results between intel and gnu on current branches (no MPI)
shared_intel_gnu_regression:
  stage: regression
  extends:
    - .tmpl_sharedrunner          # needed to load modules (numdiff cmd!)
    - .tmpl_before_script_modules # needed to load modules (numdiff cmd!)
    - .tmpl_script_regression
  parallel:
    matrix:
      - CMP_MODE: ["Debug"]
        OMP_MODE: ["ompOFF","ompON"]
  variables:
    CURR_CMP: intel # needed to load modules (numdiff cmd!)
    HASH_TAG_1: ${HASH_TAG}
    HASH_TAG_2: ${HASH_TAG}
    CURR_CMP_1: ${CURR_CMP}
    CURR_CMP_2: gnu
    CASENAME_1: ${HASH_TAG_1}_${CURR_CMP_1}_${CMP_MODE}_${OMP_MODE}_mpiOFF
    CASENAME_2: ${HASH_TAG_2}_${CURR_CMP_2}_${CMP_MODE}_${OMP_MODE}_mpiOFF
  needs:
    - job: sharedrunner_intel_run
      artifacts: true
    - job: sharedrunner_gnu_run
      artifacts: true
