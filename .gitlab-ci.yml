# =================================================================================================================================
# Stages to be executed, each stage is a collection of jobs pointing to the stage
# =================================================================================================================================

stages:
  - env
  - build
  - run
  - regression
  - postprocessing
  - publish

workflow:
  name: 'Pipeline for branch $CI_COMMIT_REF_NAME vs $HASH_TAG_REFERENCE'
  rules:
    # disable the pipeline for merge requests (to avoid duplicate pipelines)
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
      when: never
    # compare tags and develop vs "main" / latest release, rarely makes sense otherwise
    - if: $CI_COMMIT_TAG || $CI_COMMIT_REF_NAME == "develop"
      when: always
      variables:
        HASH_TAG_REFERENCE: main
    # otherwise always run the pipeline (e.g. on every push)
    - when: always

# =================================================================================================================================
# GLOBALS
# =================================================================================================================================

variables:
  GIT_STRATEGY: fetch
  HASH_TAG: $CI_COMMIT_REF_NAME
  HASH_TAG_REFERENCE:
    value: develop
    description: "The reference branch/tag to compare against"
  MINIMAL_PIPELINE:
    value: ""
    options: ["", "true", "false"]
    description: "''true'' to run only minimal tests, ''false'' to run all tests, '''' to run only minimal tests for ''.*gitlab[-_]ci.*'' branches"
  NIGHTLY_PIPELINE:
    value: "false"
    options: ["true", "false"]
    description: "''true'' to run additional ''nightly'' tests, ''false'' to run default tests"
  PAGES_PIPELINE:
    value: "false"
    options: ["true", "false"]
    description: "''true'' to deploy GitLab Pages"
  PYTEST_EXEC_CMD: "python -m pytest -v -rA --tb=short"
  # global defaults for the pytest -m and -k options (can be reassigned at the job level!)
  PYTEST_MARKER_OPTS: "example"
  PYTEST_KEY_OPTS: ""               # default value
  PYTEST_EXTRA_OPTS: ""
  PRIVATE_RUNNER_PIPELINE:
   value: "true"
   options: ["true", "false"]
   description: "''true'' to include the SLURM jobs in the pipeline, ''false'' to exclude them from the pipeline"

#  GLOBAL_CACHE_PATH: "/home/gitlab-runner/globalcache/${CI_PIPELINE_ID}_${CI_COMMIT_REF_NAME}"

# =================================================================================================================================
# SHORT SYNTAX EXPLANATIONS FOR THE JOB, FOR DETAILS VISIT:    ===> https://docs.gitlab.com/ce/ci/yaml/   <===
# "stage:"         makes the job part of a stage defined above
# "tags:"          selects the runner
# "only:"          restricts the execution of the job to a git branch or tag
# "before_script:" shell commands to be executed before the main script.
# "script:"        shell commands for the test. If a shell command exits with >0, the job is marked as "failed", else as "passed".
#                  commands after a failing one are not executed anymore!
# "after_script:"  shell commands after passed OR failed script. Careful, the current directory is always the root of the repo!
# "artifacts:"     keep data from the job which is uploaded to gitlab.com. You really should set a duration to expiration.
#                  "when:" can be either on_failure, on_success or always
#
# => SCRIPT SYNTAX CAN BE CHECKED ON GITLAB with the "CI LINT" tool
#
# =================================================================================================================================

# =================================================================================================================================
# ISSUE FOUND WITH PARALLEL MATRICES
# =================================================================================================================================

#  parallel:
#    matrix:
#      - CMP_MODE: ["Debug"]
#        OMP_MODE: ["ompON"] #only one element/variable in matrix: causes CI dependency line to break
#                             check issue report: https://gitlab.com/gitlab-org/gitlab/-/issues/428679
#                             workaround is to use the keyword "variables:" instead (like below)
#  variables:
#    HASH_TAG: ${HASH_TAG_REFERENCE}
#    CMP_MODE: "Debug"
#    OMP_MODE: "ompON"


# =================================================================================================================================
# INCLUDE TEMPLATES & JOBS 
# =================================================================================================================================

include:

  # ============================
  # script templates
  # ============================
  - local: CI_templates/scripts.yml

  # ============================
  # stage env jobs
  # ============================
  - local: CI_templates/env.yml
    inputs:
      env: .mpcdfci_intel2023
      rules: .rules_minimal

  - local: CI_templates/env.yml
    inputs:
      env: .mpcdfci_intel_latest
      rules: .rules_minimal
  
  - local: CI_templates/env.yml
    inputs:
      env: .mpcdfci_gcc13

  - local: CI_templates/env.yml
    inputs:
      env: .mpcdfci_nvhpc23

  # MPI
  - local: CI_templates/env.yml
    inputs:
      env: .mpcdfci_intel2023_impi
      rules: .rules_minimal

  - local: CI_templates/env.yml
    inputs:
      env: .mpcdfci_intel_impi_latest
      rules: .rules_minimal

  - local: CI_templates/env.yml
    inputs:
      env: .mpcdfci_gcc_openmpi_latest

  # Private runners
  # ---------------

  # Raven private runner (Intel)
  - local: CI_templates/env.yml
    inputs:
      env: .raven_intel
      rules: .rules_private_runner_minimal

  # Raven private runner (Gnu)
  - local: CI_templates/env.yml
    inputs:
      env: .raven_gcc
      rules: .rules_private_runner

  # Raven private runner (Nvidia)
  - local: CI_templates/env.yml
    inputs:
      env: .raven_nvhpc
      rules: .rules_private_runner

  # Viper private runner (Gnu)
  - local: CI_templates/env.yml
    inputs:
      env: .viper_gcc
      rules: .rules_private_runner_minimal

  # MPI

  # Raven private runner (Intel + IntelMPI)
  - local: CI_templates/env.yml
    inputs:
      env: .raven_intel_impi
      rules: .rules_private_runner_nightly

  # Raven private runner (Gnu + OpenMPI)
  - local: CI_templates/env.yml
    inputs:
      env: .raven_gcc_openmpi
      rules: .rules_private_runner_minimal

  # Viper private runner (Gnu + OpenMPI)
  - local: CI_templates/env.yml
    inputs:
      env: .viper_gcc_openmpi
      rules: .rules_private_runner_minimal

  # ============================
  # stage build jobs
  # ============================
  - local: CI_templates/build.yml
    inputs:
      env: .mpcdfci_intel2023
      rules: .rules_minimal

  - local: CI_templates/build.yml
    inputs:
      env: .mpcdfci_intel_latest
      rules: .rules_minimal

  - local: CI_templates/build.yml
    inputs:
      env: .mpcdfci_gcc13

  - local: CI_templates/build.yml
    inputs:
      env: .mpcdfci_nvhpc23

  # MPI
  - local: CI_templates/build.yml
    inputs:
      env: .mpcdfci_intel2023_impi
      vars: .vars_matrix_mpi_build
      cmake-opts: .cmake_mpi_opts
      rules: .rules_minimal

  - local: CI_templates/build.yml
    inputs:
      env: .mpcdfci_intel_impi_latest
      vars: .vars_matrix_mpi_build
      cmake-opts: .cmake_mpi_opts
      rules: .rules_minimal

  - local: CI_templates/build.yml
    inputs:
      env: .mpcdfci_gcc_openmpi_latest
      vars: .vars_matrix_mpi_build
      cmake-opts: .cmake_mpi_opts

  # converter-only
  - local: CI_templates/build.yml
    inputs:
      env: .mpcdfci_intel2023
      build-postfix: _only_converter
      cmake-opts: .cmake_only_converter
      rules: .rules_minimal

  - local: CI_templates/build.yml
    inputs:
      env: .mpcdfci_intel_latest
      build-postfix: _only_converter
      cmake-opts: .cmake_only_converter
      rules: .rules_minimal

  - local: CI_templates/build.yml
    inputs:
      env: .mpcdfci_gcc13
      build-postfix: _only_converter
      cmake-opts: .cmake_only_converter

  - local: CI_templates/build.yml
    inputs:
      env: .mpcdfci_nvhpc23
      build-postfix: _only_converter
      cmake-opts: .cmake_only_converter

  # reference tag
  - local: CI_templates/build.yml
    inputs:
      env: .mpcdfci_intel2023
      build-postfix: _tag
      vars: .vars_matrix_build_tag
      rules: .rules_minimal

  # reference tag
  - local: CI_templates/build.yml
    inputs:
      env: .mpcdfci_intel_latest
      build-postfix: _tag
      vars: .vars_matrix_build_tag
      rules: .rules_minimal

  # release tag + MPI
  - local: CI_templates/build.yml
    inputs:
      env: .mpcdfci_intel_impi_latest
      build-postfix: _tag
      vars: .vars_matrix_mpi_build_tag
      cmake-opts: .cmake_mpi_opts
      rules: .rules_minimal

  # Private runners
  # ---------------

  # Raven private runner (Intel)
  - local: CI_templates/build.yml
    inputs:
      env: .raven_intel
      vars: .vars_raven_build
      rules: .rules_private_runner_minimal

  # Raven private runner (Gnu)
  - local: CI_templates/build.yml
    inputs:
      env: .raven_gcc
      vars: .vars_raven_build
      rules: .rules_private_runner

  # Raven private runner (Nvidia)
  - local: CI_templates/build.yml
    inputs:
      env: .raven_nvhpc
      vars: .vars_raven_build
      rules: .rules_private_runner

  # Viper private runner (Gnu)
  - local: CI_templates/build.yml
    inputs:
      env: .viper_gcc
      vars: .vars_viper_build
      rules: .rules_private_runner_minimal

  # reference tag
  # Raven private runner (Intel)
  - local: CI_templates/build.yml
    inputs:
      env: .raven_intel
      build-postfix: _tag
      vars: .vars_raven_build_tag
      rules: .rules_private_runner_minimal

  # FAILS until `feature_private-runners` is merged into `develop` due to missing `CMakeLists.txt` Viper configuration
  # reference tag
  # Viper private runner (Gnu)
  - local: CI_templates/build.yml
    inputs:
      env: .viper_gcc
      build-postfix: _tag
      vars: .vars_viper_build_tag
      rules: .rules_private_runner

  # MPI

  # Raven private runner (Intel + IntelMPI)
  - local: CI_templates/build.yml
    inputs:
      env: .raven_intel_impi
      vars: .vars_raven_build
      cmake-opts: .cmake_mpi_opts
      rules: .rules_private_runner_nightly

  # Raven private runner (Gnu + OpenMPI)
  - local: CI_templates/build.yml
    inputs:
      env: .raven_gcc_openmpi
      vars: .vars_raven_build
      cmake-opts: .cmake_mpi_opts
      rules: .rules_private_runner_minimal

  # Viper private runner (Gnu + OpenMPI)
  - local: CI_templates/build.yml
    inputs:
      env: .viper_gcc_openmpi
      vars: .vars_viper_build  ### .vars_viper_mpi_build
      cmake-opts: .cmake_mpi_opts
      rules: .rules_private_runner_minimal

  # ============================
  # stage run jobs
  # ============================
  - local: CI_templates/run.yml
    inputs:
      env: .mpcdfci_intel2023
      rules: .rules_minimal

  - local: CI_templates/run.yml
    inputs:
      env: .mpcdfci_intel_latest
      rules: .rules_minimal

  - local: CI_templates/run.yml
    inputs:
      env: .mpcdfci_gcc13

  - local: CI_templates/run.yml
    inputs:
      env: .mpcdfci_nvhpc23
      vars: .vars_matrix_run_nvhpc

  # debugrun
  - local: CI_templates/run.yml
    inputs:
      env: .mpcdfci_intel2023
      run-postfix: _debugrun
      vars: .vars_matrix_run_debugrun
      rules: .rules_nightly

  # debugrun
  - local: CI_templates/run.yml
    inputs:
      env: .mpcdfci_intel_latest
      run-postfix: _debugrun
      vars: .vars_matrix_run_debugrun
      rules: .rules_nightly

  - local: CI_templates/run.yml
    inputs:
      env: .mpcdfci_gcc13
      run-postfix: _debugrun
      vars: .vars_matrix_run_debugrun
      rules: .rules_nightly

  - local: CI_templates/run.yml
    inputs:
      env: .mpcdfci_nvhpc23
      run-postfix: _debugrun
      vars: .vars_matrix_run_debugrun
      rules: .rules_nightly

  # MPI
  - local: CI_templates/run.yml
    inputs:
      env: .mpcdfci_intel2023_impi
      vars: .vars_matrix_mpi_run
      rules: .rules_minimal

  - local: CI_templates/run.yml
    inputs:
      env: .mpcdfci_intel_impi_latest
      vars: .vars_matrix_mpi_run
      rules: .rules_minimal

  - local: CI_templates/run.yml
    inputs:
      env: .mpcdfci_gcc_openmpi_latest
      vars: .vars_matrix_mpi_run

  # reference tag
  - local: CI_templates/run.yml
    inputs:
      env: .mpcdfci_intel2023
      run-postfix: _tag
      build-postfix: _tag
      vars: .vars_matrix_run_tag
      rules: .rules_minimal

  # reference tag
  - local: CI_templates/run.yml
    inputs:
      env: .mpcdfci_intel_latest
      run-postfix: _tag
      build-postfix: _tag
      vars: .vars_matrix_run_tag
      rules: .rules_minimal

  # reference tag + MPI
  - local: CI_templates/run.yml
    inputs:
      env: .mpcdfci_intel_impi_latest
      run-postfix: _tag
      build-postfix: _tag
      vars: .vars_matrix_mpi_run_tag
      rules: .rules_minimal

  # Private runners
  # ---------------

  # Raven private runner - login nodes (Intel), left here for reference, should never be executed
  - local: CI_templates/run.yml
    inputs:
      env: .raven_intel
      vars: .vars_raven_run
      rules: .rules_never

  # Raven private runner (Intel) + srun
  - local: CI_templates/run.yml
    inputs:
      env: .raven_intel
      vars: .vars_raven_run_slurm
      slurm-postfix: _slurm
      rules: .rules_private_runner_minimal

  # Viper private runner (Gnu) + srun
  - local: CI_templates/run.yml
    inputs:
      env: .viper_gcc
      vars: .vars_viper_run_slurm
      slurm-postfix: _slurm
      rules: .rules_private_runner_minimal

  # Viper private runner (debugrun Gnu) + srun
  - local: CI_templates/run.yml
    inputs:
      env: .viper_gcc
      vars: .vars_viper_run_debugrun_slurm
      run-postfix: _debugrun
      slurm-postfix: _slurm
      rules: .rules_private_runner_nightly

  # MPI

  # Raven private runner (Intel + IntelMPI) + srun
  # this one CRASHES on Raven due to srun. If executed with mpirun, it works!
  - local: CI_templates/run.yml
    inputs:
      env: .raven_intel_impi
      vars: .vars_raven_mpi_run_slurm
      slurm-postfix: _slurm
      rules: .rules_private_runner_nightly

  # Raven private runner (Gnu + OpenMPI) + srun
  - local: CI_templates/run.yml
    inputs:
      env: .raven_gcc_openmpi
      vars: .vars_raven_mpi_run_slurm
      slurm-postfix: _slurm
      rules: .rules_private_runner_minimal

  # Viper private runner (Gnu + OpenMPI) + srun
  - local: CI_templates/run.yml
    inputs:
      env: .viper_gcc_openmpi
      vars: .vars_viper_mpi_run_slurm
      slurm-postfix: _slurm
      rules: .rules_private_runner_minimal

  # ============================
  # stage regression jobs
  # ============================
  # defined explicitly, also containing rules
  - local: CI_templates/regression.yml

  # ============================
  # stage postprocessing jobs
  # ============================
  - local: CI_templates/postprocessing.yml
    inputs:
      env: .mpcdfci_intel2023
      rules: .rules_minimal

  - local: CI_templates/postprocessing.yml
    inputs:
      env: .mpcdfci_intel_latest
      rules: .rules_minimal

  - local: CI_templates/postprocessing.yml
    inputs:
      env: .mpcdfci_gcc13

  - local: CI_templates/postprocessing.yml
    inputs:
      env: .mpcdfci_nvhpc23

  # ============================
  # stage converter jobs: postprocessing
  # ============================
  - local: CI_templates/converters.yml
    inputs:
      env: .mpcdfci_intel2023
      build-postfix: _only_converter
      rules: .rules_minimal

  - local: CI_templates/converters.yml
    inputs:
      env: .mpcdfci_intel_latest
      build-postfix: _only_converter
      rules: .rules_minimal

  - local: CI_templates/converters.yml
    inputs:
      env: .mpcdfci_gcc13
      build-postfix: _only_converter

  - local: CI_templates/converters.yml
    inputs:
      env: .mpcdfci_nvhpc23
      build-postfix: _only_converter


  # ============================
  # stage publish jobs
  # ============================
  - local: CI_templates/pages.yml


# =================================================================================================================================
# TEMPLATES INDEPENDENT OF STAGE
# =================================================================================================================================

# ____________________________
# Rules templates
# reference: https://docs.gitlab.com/ee/ci/yaml/#rulesif
# and: https://docs.gitlab.com/ee/ci/yaml/#when
# An `- if:` beyond the first `- if:` is an "else if". And the last part (like `- when:` , does not have a condition, so it corresponds to an "else".
# when: on_success - Run the job only when no jobs in earlier stages fail or have allow_failure: true.
# when: on_failure - Run the job only when at least one job in an earlier stage fails.
# when: always - Run the job regardless of the status of jobs in earlier stages.
# when: never - Don’t run the job
# when: manual - Run the job only when triggered manually.

.rules_default:
  rules:
    # disable this job for gitlab-ci branches or if MINIMAL_PIPELINE is set to "true"
    # MINIMAL_PIPELINE="false" overrides gitlab-ci jobs
    - if: ($CI_COMMIT_REF_NAME =~ /gitlab[-_]ci/ && $MINIMAL_PIPELINE != "false") || $MINIMAL_PIPELINE == "true"
      when: never
    - when: on_success

.rules_minimal:
  rules:
    # special variables for gitlab-ci branches or if MINIMAL_PIPELINE is set
    - if: ($CI_COMMIT_REF_NAME =~ /gitlab[-_]ci/ && $MINIMAL_PIPELINE != "false") || $MINIMAL_PIPELINE == "true"
      variables:
        PYTEST_KEY_OPTS: "(not highres) and (not _restart)"
        PYTEST_MARKER_OPTS: "shortrun"
      when: on_success
    - when: on_success

.rules_minimal_only:
  rules:
    # special variables for gitlab-ci branches or if MINIMAL_PIPELINE is set
    - if: ($CI_COMMIT_REF_NAME =~ /gitlab[-_]ci/ && $MINIMAL_PIPELINE != "false") || $MINIMAL_PIPELINE == "true"
      variables:
        PYTEST_KEY_OPTS: "(not highres) and (not _restart)"
        PYTEST_MARKER_OPTS: "shortrun"
      when: on_success
    # don't run otherwise
    - when: never

.rules_nightly:
  rules:
    # disable this job for gitlab-ci branches or if MINIMAL_PIPELINE is set
    - if: ($CI_COMMIT_REF_NAME =~ /gitlab[-_]ci/ && $MINIMAL_PIPELINE != "false") || $MINIMAL_PIPELINE == "true"
      when: never
    # only run this job in the nightly pipeline
    - if: $NIGHTLY_PIPELINE == "true"
      when: on_success
    - when: never

.rules_private_runner:
  rules:
    # disable this job for non-protected branches
    - if: $CI_COMMIT_REF_PROTECTED == "false"
      when: never
    # disable this job for´ gitlab-ci branches or if MINIMAL_PIPELINE="true" or $PRIVATE_RUNNER_PIPELINE="false"
    - if: $PRIVATE_RUNNER_PIPELINE == "false"
      when: never
    - if: ($CI_COMMIT_REF_NAME =~ /gitlab[-_]ci/ && $MINIMAL_PIPELINE != "false") || $MINIMAL_PIPELINE == "true"
      when: never
    - when: on_success

.rules_private_runner_minimal:
  rules:
    # disable this job for non-protected branches
    - if: $CI_COMMIT_REF_PROTECTED == "false"
      when: never
    # disable this job only for $PRIVATE_RUNNER_PIPELINE="false"
    - if: $PRIVATE_RUNNER_PIPELINE == "false"
      when: never
    # special variables for gitlab-ci branches or if MINIMAL_PIPELINE is set
    - if: ($CI_COMMIT_REF_NAME =~ /gitlab[-_]ci/ && $MINIMAL_PIPELINE != "false") || $MINIMAL_PIPELINE == "true"
      when: on_success
    - when: on_success

.rules_private_runner_nightly:
  rules:
    # disable this job for non-protected branches
    - if: $CI_COMMIT_REF_PROTECTED == "false"
      when: never
    # disable this job for $PRIVATE_RUNNER_PIPELINE="false"
    - if: $PRIVATE_RUNNER_PIPELINE == "false"
      when: never
    # special variables for gitlab-ci branches or if MINIMAL_PIPELINE is set
    - if: ($CI_COMMIT_REF_NAME =~ /gitlab[-_]ci/ && $MINIMAL_PIPELINE != "false") || $MINIMAL_PIPELINE == "true"
      when: never
    # only run this job in the nightly pipeline
    - if: $NIGHTLY_PIPELINE == "true"
      when: on_success
    - when: never

.rules_pages:
  rules:
    - if: $CI_COMMIT_REF_NAME == "develop" || $PAGES_PIPELINE == "true"
      when: always
    # allow manual triggering for pipelines where pages didn't run
    - when: manual
      allow_failure: true # workaround to disable reporting the pipeline as "Blocked"

.rules_never:
  rules:
    - when: never

.vars_dirs_artifacts:
  variables:
    BUILDNAME: ${HASH_TAG}_${CMAKE_HOSTNAME}_${CURR_CMP}_${CMP_MODE}_${OMP_MODE}_${MPI_MODE}
    CASENAME: ${HASH_TAG}_${CMAKE_HOSTNAME}_${CURR_CMP}_${CMP_MODE}_${OMP_MODE}_${MPI_MODE}${MPI_RNKS_MODE}

# ____________________________
# MPCDF new Docker images
# (each providing a toolchain based on a single combination of compiler and MPI variant)

# MPCDF Docker image intel_2023_1_0_x:latest
.mpcdfci_intel2023:
  image: gitlab-registry.mpcdf.mpg.de/mpcdf/ci-module-image/intel_2023_1_0_x:latest
  tags:
    - shared
  variables:
    CMAKE_HOSTNAME: "mpcdfcirunner"
    CURR_CMP: "intel_ifort"
    MPI_MODE: "mpiOFF"
    MPI_RNKS_MODE: ""
    OMP_NUM_THR: "4"

# MPCDF Docker image intel:latest
.mpcdfci_intel_latest:
  image: gitlab-registry.mpcdf.mpg.de/mpcdf/ci-module-image/intel:latest
  tags:
    - shared
  variables:
    CMAKE_HOSTNAME: "mpcdfcirunner"
    CURR_CMP: "intel"
    MPI_MODE: "mpiOFF"
    MPI_RNKS_MODE: ""
    OMP_NUM_THR: "4"

# MPCDF Docker image intel-impi:2023_2021
.mpcdfci_intel2023_impi:
  image: gitlab-registry.mpcdf.mpg.de/mpcdf/ci-module-image/intel_2023_1_0_x-impi_2021_9:latest
  tags:
    - shared
  variables:
    CMAKE_HOSTNAME: "mpcdfcirunner"
    CURR_CMP: "intel_mpiifort"
    MPI_MODE: "mpiON"
    MPI_RNKS_MODE: "_nranks${MPI_RNKS}"
    OMP_NUM_THR: "2"

# MPCDF Docker image intel-impi:latest
.mpcdfci_intel_impi_latest:
  image: gitlab-registry.mpcdf.mpg.de/mpcdf/ci-module-image/intel-impi:latest
  tags:
    - shared
  variables:
    CMAKE_HOSTNAME: "mpcdfcirunner"
    CURR_CMP: "intel_mpi"
    MPI_MODE: "mpiON"
    MPI_RNKS_MODE: "_nranks${MPI_RNKS}"
    OMP_NUM_THR: "2"

# MPCDF Docker image gcc_13:latest
.mpcdfci_gcc13:
  image: gitlab-registry.mpcdf.mpg.de/mpcdf/ci-module-image/gcc_13:latest
  tags:
    - shared
  variables:
    CMAKE_HOSTNAME: "mpcdfcirunner"
    CURR_CMP: "gnu"
    MPI_MODE: "mpiOFF"
    MPI_RNKS_MODE: ""
    OMP_NUM_THR: "4"

# MPCDF Docker image gcc-openmpi:latest
.mpcdfci_gcc_openmpi_latest:
  image: gitlab-registry.mpcdf.mpg.de/mpcdf/ci-module-image/gcc-openmpi:latest
  tags:
    - shared
  variables:
    CMAKE_HOSTNAME: "mpcdfcirunner"
    CURR_CMP: "gnu_mpi"
    MPI_MODE: "mpiON"
    MPI_RNKS_MODE: "_nranks${MPI_RNKS}"
    OMP_NUM_THR: "2"

# MPCDF Docker image nvhpcsdk_23:latest
.mpcdfci_nvhpc23:
  image: gitlab-registry.mpcdf.mpg.de/mpcdf/ci-module-image/nvhpcsdk_23:latest
  tags:
    - shared
  variables:
    CMAKE_HOSTNAME: "mpcdfcirunner"
    CURR_CMP: "nvidia"
    MPI_MODE: "mpiOFF"
    MPI_RNKS_MODE: ""
    OMP_NUM_THR: "4"

# hooks section must be present in all private runner jobs (all stages)
.hooks_mpcdf_runner:
  hooks:
    pre_get_sources_script:
      - module load git; module load git-lfs
      - git lfs install

# ____________________________
# MPCDF Raven GVEC private runner templates

# SLURM base variables (for both Raven and Viper)
.vars_base_slurm:
  variables:
    SLURM_JOB_NAME: ci_${CI_PROJECT_NAME}_${CI_PIPELINE_ID}_${CI_JOB_ID}
    SLURM_TIMELIMIT: "10"     # specified in minutes: 10 minutes; the format "00:10:00" does not seem to work here (gets converted to 600 and then is interpreted as 600 minutes)
    SLURM_MEM_PER_NODE: 10G
    SRUN_TIMEOUT: "3600"      # specified in seconds: wait 1 hour before killing the srun job; should not outlive the CI pipeline; NOT a prefix SLURM env variable

# Raven GVEC private runner tags
.raven:
  tags:
    - raven

.raven_intel:
  extends:
    - .raven
    - .hooks_mpcdf_runner
  variables:
    CMAKE_HOSTNAME: "raven"
    CURR_CMP: "intel"
    MPI_MODE: "mpiOFF"
    MPI_RNKS_MODE: ""
    OMP_NUM_THR: "4" #"20"

.raven_gcc:
  extends:
    - .raven
    - .hooks_mpcdf_runner
  variables:
    CMAKE_HOSTNAME: "raven"
    CURR_CMP: "gnu"
    MPI_MODE: "mpiOFF"
    MPI_RNKS_MODE: ""
    OMP_NUM_THR: "4"

.raven_nvhpc:
  extends:
    - .raven
    - .hooks_mpcdf_runner
  variables:
    CMAKE_HOSTNAME: "raven"
    CURR_CMP: "nvidia"
    MPI_MODE: "mpiOFF"
    MPI_RNKS_MODE: ""
    OMP_NUM_THR: "4"

# MPCDF Viper private runner with modules gcc/openmpi
.raven_intel_impi:
  extends:
    - .raven
    - .hooks_mpcdf_runner
  variables:
    CMAKE_HOSTNAME: "raven"
    CURR_CMP: "intel_mpi"
    MPI_MODE: "mpiON"
    MPI_RNKS_MODE: "_nranks${MPI_RNKS}"
    ###OMP_NUM_THR: "32"

# MPCDF Raven private runner with modules gcc/openmpi
.raven_gcc_openmpi:
  extends:
    - .raven
    - .hooks_mpcdf_runner
  variables:
    CMAKE_HOSTNAME: "raven"
    CURR_CMP: "gnu_mpi"
    MPI_MODE: "mpiON"
    MPI_RNKS_MODE: "_nranks${MPI_RNKS}"

#### SLURM variables for Raven
###.vars_raven_slurm:
###  extends:
###    - .vars_base_slurm
###  variables:
###    SLURM_NNODES: 1           # number of compute nodes:
###    SLURM_NTASKS_PER_NODE: 1  # number of MPI tasks per node
###    SLURM_CPUS_PER_TASK: 72   # number of OpenMP threads per MPI task
###    SLURM_NTASKS_PER_CORE: 1  # Hyperthreading: disable (set=1) / enable (set=2)

# Viper GVEC private runner tags
.viper:
  tags:
    - viper

.viper_gcc:
  extends:
    - .viper
    - .hooks_mpcdf_runner
  variables:
    CMAKE_HOSTNAME: "viper"
    CURR_CMP: "gnu"
    MPI_MODE: "mpiOFF"
    MPI_RNKS_MODE: ""
    ###OMP_NUM_THR: "4" #"20"

# MPCDF Viper private runner with modules gcc/openmpi
.viper_gcc_openmpi:
  extends:
    - .viper
    - .hooks_mpcdf_runner
  variables:
    CMAKE_HOSTNAME: "viper"
    CURR_CMP: "gnu_mpi"
    MPI_MODE: "mpiON"
    MPI_RNKS_MODE: "_nranks${MPI_RNKS}"
    ###OMP_NUM_THR: "32"

#### SLURM variables for Viper
###.vars_viper_slurm:
###  extends:
###    - .vars_base_slurm
###  variables:
###    SLURM_NNODES: 1           # number of compute nodes:
###    SLURM_NTASKS_PER_NODE: 1  # number of MPI tasks per node
###    SLURM_CPUS_PER_TASK: 128  # number of OpenMP threads per MPI task
###    SLURM_NTASKS_PER_CORE: 1  # Hyperthreading: disable (set=1) / enable (set=2)

# =================================================================================================================================
# TEMPLATES FOR STAGE "build" 
# =================================================================================================================================

# ____________________________
# ${CI_COMMIT_REF_NAME} branch/tag (CI trigger commit)

.cmake_def_opts:
  variables:
    COMPILE_GVEC: "ON"
    LINK_TO_NETCDF: "ON"
    COMPILE_CONVERTERS: "ON"
    CMAKE_DEF_OPTS: "-DCOMPILE_GVEC=${COMPILE_GVEC} -DCOMPILE_GVEC_TO_CASTOR3D=${COMPILE_CONVERTERS} -DCOMPILE_GVEC_TO_GENE=${COMPILE_CONVERTERS}  -DCOMPILE_GVEC_TO_JOREK=${COMPILE_CONVERTERS}  -DCOMPILE_GVEC_TO_HOPR=${COMPILE_CONVERTERS}  -DLINK_GVEC_TO_NETCDF=${LINK_TO_NETCDF} -DCOMPILE_GVEC_AS_STATIC_LIB=ON"

# MPI not needed/tested for converters
.cmake_mpi_opts:
  variables:
    COMPILE_GVEC: "ON"
    LINK_TO_NETCDF: "ON"
    COMPILE_CONVERTERS: "OFF"
    CMAKE_DEF_OPTS: "-DCOMPILE_GVEC=${COMPILE_GVEC} -DCOMPILE_GVEC_TO_CASTOR3D=${COMPILE_CONVERTERS} -DCOMPILE_GVEC_TO_GENE=${COMPILE_CONVERTERS}  -DCOMPILE_GVEC_TO_JOREK=${COMPILE_CONVERTERS}  -DCOMPILE_GVEC_TO_HOPR=${COMPILE_CONVERTERS}  -DLINK_GVEC_TO_NETCDF=${LINK_TO_NETCDF} -DCOMPILE_GVEC_AS_STATIC_LIB=ON"

.cmake_only_converter:
  variables:
    COMPILE_GVEC: "OFF"
    LINK_TO_NETCDF: "OFF"
    COMPILE_CONVERTERS: "ON"
    CMAKE_DEF_OPTS: "-DCOMPILE_GVEC=${COMPILE_GVEC} -DCOMPILE_GVEC_TO_CASTOR3D=${COMPILE_CONVERTERS} -DCOMPILE_GVEC_TO_GENE=${COMPILE_CONVERTERS}  -DCOMPILE_GVEC_TO_JOREK=${COMPILE_CONVERTERS}  -DCOMPILE_GVEC_TO_HOPR=${COMPILE_CONVERTERS}  -DLINK_GVEC_TO_NETCDF=${LINK_TO_NETCDF} -DCOMPILE_GVEC_AS_STATIC_LIB=ON"

.vars_matrix_build:
  parallel:
    matrix:
      - CMP_MODE: ["Debug", "Release"]
        OMP_MODE: ["ompOFF", "ompON"]

# MPI jobs
.vars_matrix_mpi_build:
  parallel:
    matrix:
      - CMP_MODE: ["Debug", "Release"]
        OMP_MODE: ["ompOFF", "ompON"]

# Raven private runner
.vars_raven_build:
  variables:
    CMP_MODE: "Release"
    OMP_MODE: "ompON"

# Viper private runner
.vars_viper_build:
  variables:
    CMP_MODE: "Release"
    OMP_MODE: "ompON"

###.vars_viper_mpi_build:
###  variables:
###    CMP_MODE: "Release"
###    OMP_MODE: "ompON"

# ____________________________
# ${HASH_TAG} branch (release version)

.vars_matrix_build_tag:
  extends: .vars_matrix_build
  variables:
    HASH_TAG: ${HASH_TAG_REFERENCE}

# MPI jobs
.vars_matrix_mpi_build_tag:
  extends: .vars_matrix_mpi_build
  variables:
    HASH_TAG: ${HASH_TAG_REFERENCE}

# Raven private runner
.vars_raven_build_tag:
  extends: .vars_raven_build
  variables:
    HASH_TAG: ${HASH_TAG_REFERENCE}

# Viper private runner
.vars_viper_build_tag:
  extends: .vars_viper_build
  variables:
    HASH_TAG: ${HASH_TAG_REFERENCE}


# =================================================================================================================================
# TEMPLATES FOR STAGE "run"
# =================================================================================================================================

# ____________________________
# ${CI_COMMIT_REF_NAME} branch (CI trigger commit)

.vars_matrix_run:
  parallel:
    matrix:
      - CMP_MODE: ["Debug"]
        OMP_MODE: ["ompOFF","ompON"]
      - CMP_MODE: ["Release"]
        OMP_MODE: ["ompON"]

.vars_matrix_run_nvhpc:
  parallel:
    matrix:
      - CMP_MODE: ["Debug","Release"]
        OMP_MODE: ["ompOFF","ompON"]

# debug runs overwrite the PYTEST_MARKER_OPTS and PYTEST_KEY_OPTS!
.vars_matrix_run_debugrun:
  extends: .vars_matrix_run
  variables:
    PYTEST_MARKER_OPTS: "debugrun"
    PYTEST_KEY_OPTS: "(not highres) and (not _restart) and (not w7x_from_vmec)"

# there are different issues with MPI_RNKS>4 in both runners
.vars_matrix_mpi_run:
  parallel:
    matrix:
      - CMP_MODE: ["Debug","Release"]
        OMP_MODE: ["ompOFF","ompON"]
        MPI_RNKS: ["1","2"]

# Raven private runner (vars for runs on login nodes)
.vars_raven_run:   # to be extended in the `regression` stage (allow_failure can NOT be in this template)
  extends: .vars_raven_build

# Raven private runner (runs on SLURM queues via srun)
.vars_raven_run_slurm:
  extends:
    - .vars_raven_build
    - .vars_base_slurm
  variables:
    SLURM_NNODES: 1           # number of compute nodes:
    SLURM_NTASKS_PER_NODE: 1  # number of MPI tasks per node
    SLURM_CPUS_PER_TASK: 72   # number of OpenMP threads per MPI task
    SLURM_NTASKS_PER_CORE: 1  # Hyperthreading: disable (set=1) / enable (set=2)
    OMP_NUM_THR: ${SLURM_CPUS_PER_TASK}

# MPI
.vars_raven_mpi_run_slurm:
  extends:
    - .vars_raven_build
    - .vars_base_slurm
  variables:
    SLURM_NNODES: 1           # number of compute nodes:
    SLURM_NTASKS_PER_NODE: 2  # number of MPI tasks per node
    SLURM_CPUS_PER_TASK: 36   # number of OpenMP threads per MPI task
    SLURM_NTASKS_PER_CORE: 1  # Hyperthreading: disable (set=1) / enable (set=2)
    OMP_NUM_THR: ${SLURM_CPUS_PER_TASK}

# Raven private runner (runs on SLURM queues via srun)
.vars_viper_run_slurm:
  extends:
    - .vars_viper_build
    - .vars_base_slurm
  variables:
    SLURM_NNODES: 1           # number of compute nodes:
    SLURM_NTASKS_PER_NODE: 1  # number of MPI tasks per node
    SLURM_CPUS_PER_TASK: 128  # number of OpenMP threads per MPI task
    SLURM_NTASKS_PER_CORE: 1  # Hyperthreading: disable (set=1) / enable (set=2)
    OMP_NUM_THR: ${SLURM_CPUS_PER_TASK}

.vars_viper_run_debugrun_slurm:
  extends: .vars_viper_run_slurm
  variables:
    PYTEST_MARKER_OPTS: "debugrun"
    PYTEST_KEY_OPTS: "(not highres) and (not _restart) and (not w7x_from_vmec)"

# MPI
.vars_viper_mpi_run_slurm:
  extends:
    - .vars_viper_build
    - .vars_base_slurm
  variables:
    SLURM_NNODES: 1           # number of compute nodes:
    SLURM_NTASKS_PER_NODE: 2  # number of MPI tasks per node
    SLURM_CPUS_PER_TASK: 64   # number of OpenMP threads per MPI task
    SLURM_NTASKS_PER_CORE: 1  # Hyperthreading: disable (set=1) / enable (set=2)
    OMP_NUM_THR: ${SLURM_CPUS_PER_TASK}

# ____________________________
# ${HASH_TAG} branch (release version)

.vars_matrix_run_tag:
  extends: .vars_matrix_run
  variables:
    HASH_TAG: ${HASH_TAG_REFERENCE}

.vars_matrix_mpi_run_tag:
  extends: .vars_matrix_mpi_run
  variables:
    HASH_TAG: ${HASH_TAG_REFERENCE}

.vars_matrix_run_nvhpc_tag:
  extends: .vars_matrix_run_nvhpc
  variables:
    HASH_TAG: ${HASH_TAG_REFERENCE}

# MPI not needed/tested for converters


# =================================================================================================================================
# TEMPLATES FOR STAGE "post"
# =================================================================================================================================

.vars_matrix_post:
  parallel:
    matrix:
      - CMP_MODE: ["Debug","Release"]
        OMP_MODE: ["ompON"]
  variables:
    MPI_MODE: "mpiOFF"
    MPI_RNKS_MODE: ""
    OMP_NUM_THR: "2"

.vars_matrix_conv:
  variables:
    CMP_MODE: "Release"
    OMP_MODE: "ompON"
    MPI_MODE: "mpiOFF"
    MPI_RNKS_MODE: ""
    OMP_NUM_THR: "2"
